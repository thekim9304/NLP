# Week 11 - 머신러닝 모델이 공부하는 방법
[본문 Week11](https://jiho-ml.com/weekly-nlp-11/)
#### cost function
#### gradient descent

# Week 12 - AI 모델에게도 예비 고사와 수능이 있다고요?
[본문 Week12](https://jiho-ml.com/weekly-nlp-12/)
#### cross-validation

- 전체 데이터 중 10~30%를 평가용 데이터로 할당 (이 방식을 holdout method라고함)
- validation set = 예비 고사, Test set = 수능

#### Validation set의 존재 목적
- 어떤 모델 구조, 크기를 사용할지, 모델 변수들은 무엇으로 할지 (model hyperparameter)
- 얼마나 오래, 얼마나 빠르게 학습을 시킬 것인지 (learning hyperparameter)

#### Validation set에서 성능이 안좋았다면?
- 학습 데이터 늘리기
- 모델 구조 변경
- 학습 시간 늘리기

#### 머신 러닝 모델 학습 잘 시키는 팁
- 데이터를 무작위로 잘 섞기(섞어서 set 나누기)
- Validation/Test set에 있는 데이터가 Training set과 중복되는지 확인
- class 간의 분포를 잘 맞추기 - regression에서는 평균값이나 표준편차 맞추기
- 데이터 수가 적으면 k-fold cross validation 이용
- test set은 마지막까지 보지말기
